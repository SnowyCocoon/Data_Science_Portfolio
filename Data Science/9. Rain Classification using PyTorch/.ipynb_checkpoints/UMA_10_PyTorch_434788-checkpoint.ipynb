{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dominik Strza≈Çko - PyTorch - Przewidywanie deszczu w Australii \n",
    "\n",
    "## https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n",
    "\n",
    "## Plik .csv jako .zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importy bibliotek oraz wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f009e25e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 45\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145455</th>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>31.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1024.6</td>\n",
       "      <td>1020.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145456</th>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>3.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNW</td>\n",
       "      <td>22.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>1019.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145457</th>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>5.4</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>37.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145458</th>\n",
       "      <td>2017-06-24</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>7.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145459</th>\n",
       "      <td>2017-06-25</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>14.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESE</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145460 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
       "0       2008-12-01   Albury     13.4     22.9       0.6          NaN   \n",
       "1       2008-12-02   Albury      7.4     25.1       0.0          NaN   \n",
       "2       2008-12-03   Albury     12.9     25.7       0.0          NaN   \n",
       "3       2008-12-04   Albury      9.2     28.0       0.0          NaN   \n",
       "4       2008-12-05   Albury     17.5     32.3       1.0          NaN   \n",
       "...            ...      ...      ...      ...       ...          ...   \n",
       "145455  2017-06-21    Uluru      2.8     23.4       0.0          NaN   \n",
       "145456  2017-06-22    Uluru      3.6     25.3       0.0          NaN   \n",
       "145457  2017-06-23    Uluru      5.4     26.9       0.0          NaN   \n",
       "145458  2017-06-24    Uluru      7.8     27.0       0.0          NaN   \n",
       "145459  2017-06-25    Uluru     14.9      NaN       0.0          NaN   \n",
       "\n",
       "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  \\\n",
       "0            NaN           W           44.0          W  ...        71.0   \n",
       "1            NaN         WNW           44.0        NNW  ...        44.0   \n",
       "2            NaN         WSW           46.0          W  ...        38.0   \n",
       "3            NaN          NE           24.0         SE  ...        45.0   \n",
       "4            NaN           W           41.0        ENE  ...        82.0   \n",
       "...          ...         ...            ...        ...  ...         ...   \n",
       "145455       NaN           E           31.0         SE  ...        51.0   \n",
       "145456       NaN         NNW           22.0         SE  ...        56.0   \n",
       "145457       NaN           N           37.0         SE  ...        53.0   \n",
       "145458       NaN          SE           28.0        SSE  ...        51.0   \n",
       "145459       NaN         NaN            NaN        ESE  ...        62.0   \n",
       "\n",
       "        Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  \\\n",
       "0              22.0       1007.7       1007.1       8.0       NaN     16.9   \n",
       "1              25.0       1010.6       1007.8       NaN       NaN     17.2   \n",
       "2              30.0       1007.6       1008.7       NaN       2.0     21.0   \n",
       "3              16.0       1017.6       1012.8       NaN       NaN     18.1   \n",
       "4              33.0       1010.8       1006.0       7.0       8.0     17.8   \n",
       "...             ...          ...          ...       ...       ...      ...   \n",
       "145455         24.0       1024.6       1020.3       NaN       NaN     10.1   \n",
       "145456         21.0       1023.5       1019.1       NaN       NaN     10.9   \n",
       "145457         24.0       1021.0       1016.8       NaN       NaN     12.5   \n",
       "145458         24.0       1019.4       1016.5       3.0       2.0     15.1   \n",
       "145459         36.0       1020.2       1017.9       8.0       8.0     15.0   \n",
       "\n",
       "        Temp3pm  RainToday  RainTomorrow  \n",
       "0          21.8         No            No  \n",
       "1          24.3         No            No  \n",
       "2          23.2         No            No  \n",
       "3          26.5         No            No  \n",
       "4          29.7         No            No  \n",
       "...         ...        ...           ...  \n",
       "145455     22.4         No            No  \n",
       "145456     24.5         No            No  \n",
       "145457     26.1         No            No  \n",
       "145458     26.0         No            No  \n",
       "145459     20.9         No           NaN  \n",
       "\n",
       "[145460 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocesing danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Rainfall', 'Humidity3pm', 'Humidity9am', 'RainToday', 'RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rainfall  Humidity3pm  Humidity9am RainToday RainTomorrow\n",
       "0       0.6         22.0         71.0        No           No\n",
       "1       0.0         25.0         44.0        No           No\n",
       "2       0.0         30.0         38.0        No           No\n",
       "3       0.0         16.0         45.0        No           No\n",
       "4       1.0         33.0         82.0        No           No"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domstr2\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "df['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "df['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145455</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145456</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145457</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145458</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145459</th>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145460 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rainfall  Humidity3pm  Humidity9am  RainToday  RainTomorrow\n",
       "0            0.6         22.0         71.0        0.0           0.0\n",
       "1            0.0         25.0         44.0        0.0           0.0\n",
       "2            0.0         30.0         38.0        0.0           0.0\n",
       "3            0.0         16.0         45.0        0.0           0.0\n",
       "4            1.0         33.0         82.0        0.0           0.0\n",
       "...          ...          ...          ...        ...           ...\n",
       "145455       0.0         24.0         51.0        0.0           0.0\n",
       "145456       0.0         21.0         56.0        0.0           0.0\n",
       "145457       0.0         24.0         53.0        0.0           0.0\n",
       "145458       0.0         24.0         51.0        0.0           0.0\n",
       "145459       0.0         36.0         62.0        0.0           NaN\n",
       "\n",
       "[145460 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rainfall  Humidity3pm  Humidity9am  RainToday  RainTomorrow\n",
       "0       0.6         22.0         71.0        0.0           0.0\n",
       "1       0.0         25.0         44.0        0.0           0.0\n",
       "2       0.0         30.0         38.0        0.0           0.0\n",
       "3       0.0         16.0         45.0        0.0           0.0\n",
       "4       1.0         33.0         82.0        0.0           0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1.** Downscale-ing klas\n",
    "https://elitedatascience.com/imbalanced-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    30160\n",
       "0.0    30160\n",
       "Name: RainTomorrow, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.RainTomorrow==0.0]\n",
    "df_minority = df[df.RainTomorrow==1.0]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=30160,     # to match minority class\n",
    "                                 random_state=RANDOM_SEED) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.RainTomorrow.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domstr2\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df_downsampled.RainTomorrow);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.5\n",
       "0.0    0.5\n",
       "Name: RainTomorrow, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled.RainTomorrow.value_counts() / df_downsampled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_downsampled.drop(['RainTomorrow'], axis=1)\n",
    "y = df_downsampled[['RainTomorrow']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48256, 4]) torch.Size([48256])\n",
      "torch.Size([12064, 4]) torch.Size([12064])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
    "\n",
    "\n",
    "X_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Budowanie sieci neuronowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self, n_features): # NN Constructor\n",
    "    super(Net, self).__init__() #super constructor\n",
    "    self.fc1 = nn.Linear(n_features, 12) #Input to Hidden Layer\n",
    "    self.fc2 = nn.Linear(12, 6) #Hidden to Hidden Layer\n",
    "    self.fc3 = nn.Linear(6, 1) #Hidden to Output Layer\n",
    "    \n",
    "  def forward(self, x): #passing outputs to another layers\n",
    "    x = F.relu(self.fc1(x)) # In to Hid Layer (relu)\n",
    "    x = F.relu(self.fc2(x)) # Hid to Hid Layer (relu)\n",
    "    return torch.sigmoid(self.fc3(x)) # Hid to Out Layer (sigmoid)\n",
    "\n",
    "net = Net(X_train.shape[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Trening Modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() #Binary Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001) #Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train set - loss: 1.356, accuracy: 0.5\n",
      "Test  set - loss: 1.358, accuracy: 0.5\n",
      "\n",
      "epoch 5\n",
      "Train set - loss: 1.203, accuracy: 0.5\n",
      "Test  set - loss: 1.205, accuracy: 0.5\n",
      "\n",
      "epoch 10\n",
      "Train set - loss: 1.069, accuracy: 0.5\n",
      "Test  set - loss: 1.071, accuracy: 0.5\n",
      "\n",
      "epoch 15\n",
      "Train set - loss: 0.958, accuracy: 0.5\n",
      "Test  set - loss: 0.958, accuracy: 0.501\n",
      "\n",
      "epoch 20\n",
      "Train set - loss: 0.868, accuracy: 0.5\n",
      "Test  set - loss: 0.868, accuracy: 0.501\n",
      "\n",
      "epoch 25\n",
      "Train set - loss: 0.8, accuracy: 0.503\n",
      "Test  set - loss: 0.8, accuracy: 0.503\n",
      "\n",
      "epoch 30\n",
      "Train set - loss: 0.751, accuracy: 0.519\n",
      "Test  set - loss: 0.751, accuracy: 0.519\n",
      "\n",
      "epoch 35\n",
      "Train set - loss: 0.716, accuracy: 0.544\n",
      "Test  set - loss: 0.715, accuracy: 0.544\n",
      "\n",
      "epoch 40\n",
      "Train set - loss: 0.689, accuracy: 0.575\n",
      "Test  set - loss: 0.688, accuracy: 0.577\n",
      "\n",
      "epoch 45\n",
      "Train set - loss: 0.663, accuracy: 0.637\n",
      "Test  set - loss: 0.663, accuracy: 0.641\n",
      "\n",
      "epoch 50\n",
      "Train set - loss: 0.634, accuracy: 0.702\n",
      "Test  set - loss: 0.634, accuracy: 0.701\n",
      "\n",
      "epoch 55\n",
      "Train set - loss: 0.615, accuracy: 0.683\n",
      "Test  set - loss: 0.615, accuracy: 0.681\n",
      "\n",
      "epoch 60\n",
      "Train set - loss: 0.602, accuracy: 0.685\n",
      "Test  set - loss: 0.603, accuracy: 0.683\n",
      "\n",
      "epoch 65\n",
      "Train set - loss: 0.593, accuracy: 0.697\n",
      "Test  set - loss: 0.593, accuracy: 0.695\n",
      "\n",
      "epoch 70\n",
      "Train set - loss: 0.586, accuracy: 0.703\n",
      "Test  set - loss: 0.587, accuracy: 0.702\n",
      "\n",
      "epoch 75\n",
      "Train set - loss: 0.582, accuracy: 0.702\n",
      "Test  set - loss: 0.583, accuracy: 0.699\n",
      "\n",
      "epoch 80\n",
      "Train set - loss: 0.579, accuracy: 0.701\n",
      "Test  set - loss: 0.58, accuracy: 0.7\n",
      "\n",
      "epoch 85\n",
      "Train set - loss: 0.577, accuracy: 0.7\n",
      "Test  set - loss: 0.578, accuracy: 0.7\n",
      "\n",
      "epoch 90\n",
      "Train set - loss: 0.576, accuracy: 0.7\n",
      "Test  set - loss: 0.576, accuracy: 0.7\n",
      "\n",
      "epoch 95\n",
      "Train set - loss: 0.574, accuracy: 0.7\n",
      "Test  set - loss: 0.575, accuracy: 0.699\n",
      "\n",
      "epoch 100\n",
      "Train set - loss: 0.574, accuracy: 0.7\n",
      "Test  set - loss: 0.574, accuracy: 0.697\n",
      "\n",
      "epoch 105\n",
      "Train set - loss: 0.573, accuracy: 0.7\n",
      "Test  set - loss: 0.574, accuracy: 0.698\n",
      "\n",
      "epoch 110\n",
      "Train set - loss: 0.573, accuracy: 0.7\n",
      "Test  set - loss: 0.573, accuracy: 0.699\n",
      "\n",
      "epoch 115\n",
      "Train set - loss: 0.572, accuracy: 0.701\n",
      "Test  set - loss: 0.573, accuracy: 0.699\n",
      "\n",
      "epoch 120\n",
      "Train set - loss: 0.572, accuracy: 0.701\n",
      "Test  set - loss: 0.572, accuracy: 0.699\n",
      "\n",
      "epoch 125\n",
      "Train set - loss: 0.571, accuracy: 0.701\n",
      "Test  set - loss: 0.572, accuracy: 0.699\n",
      "\n",
      "epoch 130\n",
      "Train set - loss: 0.571, accuracy: 0.702\n",
      "Test  set - loss: 0.571, accuracy: 0.7\n",
      "\n",
      "epoch 135\n",
      "Train set - loss: 0.571, accuracy: 0.702\n",
      "Test  set - loss: 0.571, accuracy: 0.701\n",
      "\n",
      "epoch 140\n",
      "Train set - loss: 0.57, accuracy: 0.702\n",
      "Test  set - loss: 0.571, accuracy: 0.701\n",
      "\n",
      "epoch 145\n",
      "Train set - loss: 0.57, accuracy: 0.703\n",
      "Test  set - loss: 0.57, accuracy: 0.702\n",
      "\n",
      "epoch 150\n",
      "Train set - loss: 0.57, accuracy: 0.703\n",
      "Test  set - loss: 0.57, accuracy: 0.702\n",
      "\n",
      "epoch 155\n",
      "Train set - loss: 0.569, accuracy: 0.703\n",
      "Test  set - loss: 0.57, accuracy: 0.703\n",
      "\n",
      "epoch 160\n",
      "Train set - loss: 0.569, accuracy: 0.704\n",
      "Test  set - loss: 0.569, accuracy: 0.703\n",
      "\n",
      "epoch 165\n",
      "Train set - loss: 0.569, accuracy: 0.704\n",
      "Test  set - loss: 0.569, accuracy: 0.703\n",
      "\n",
      "epoch 170\n",
      "Train set - loss: 0.569, accuracy: 0.705\n",
      "Test  set - loss: 0.569, accuracy: 0.703\n",
      "\n",
      "epoch 175\n",
      "Train set - loss: 0.568, accuracy: 0.705\n",
      "Test  set - loss: 0.568, accuracy: 0.703\n",
      "\n",
      "epoch 180\n",
      "Train set - loss: 0.568, accuracy: 0.705\n",
      "Test  set - loss: 0.568, accuracy: 0.704\n",
      "\n",
      "epoch 185\n",
      "Train set - loss: 0.568, accuracy: 0.705\n",
      "Test  set - loss: 0.568, accuracy: 0.704\n",
      "\n",
      "epoch 190\n",
      "Train set - loss: 0.567, accuracy: 0.706\n",
      "Test  set - loss: 0.568, accuracy: 0.704\n",
      "\n",
      "epoch 195\n",
      "Train set - loss: 0.567, accuracy: 0.706\n",
      "Test  set - loss: 0.567, accuracy: 0.704\n",
      "\n",
      "epoch 200\n",
      "Train set - loss: 0.567, accuracy: 0.706\n",
      "Test  set - loss: 0.567, accuracy: 0.705\n",
      "\n",
      "epoch 205\n",
      "Train set - loss: 0.567, accuracy: 0.706\n",
      "Test  set - loss: 0.567, accuracy: 0.705\n",
      "\n",
      "epoch 210\n",
      "Train set - loss: 0.566, accuracy: 0.706\n",
      "Test  set - loss: 0.566, accuracy: 0.705\n",
      "\n",
      "epoch 215\n",
      "Train set - loss: 0.566, accuracy: 0.707\n",
      "Test  set - loss: 0.566, accuracy: 0.706\n",
      "\n",
      "epoch 220\n",
      "Train set - loss: 0.566, accuracy: 0.707\n",
      "Test  set - loss: 0.566, accuracy: 0.706\n",
      "\n",
      "epoch 225\n",
      "Train set - loss: 0.566, accuracy: 0.708\n",
      "Test  set - loss: 0.565, accuracy: 0.706\n",
      "\n",
      "epoch 230\n",
      "Train set - loss: 0.565, accuracy: 0.708\n",
      "Test  set - loss: 0.565, accuracy: 0.706\n",
      "\n",
      "epoch 235\n",
      "Train set - loss: 0.565, accuracy: 0.708\n",
      "Test  set - loss: 0.565, accuracy: 0.707\n",
      "\n",
      "epoch 240\n",
      "Train set - loss: 0.565, accuracy: 0.708\n",
      "Test  set - loss: 0.565, accuracy: 0.707\n",
      "\n",
      "epoch 245\n",
      "Train set - loss: 0.564, accuracy: 0.709\n",
      "Test  set - loss: 0.564, accuracy: 0.707\n",
      "\n",
      "epoch 250\n",
      "Train set - loss: 0.564, accuracy: 0.709\n",
      "Test  set - loss: 0.563, accuracy: 0.708\n",
      "\n",
      "epoch 255\n",
      "Train set - loss: 0.563, accuracy: 0.71\n",
      "Test  set - loss: 0.563, accuracy: 0.708\n",
      "\n",
      "epoch 260\n",
      "Train set - loss: 0.563, accuracy: 0.71\n",
      "Test  set - loss: 0.563, accuracy: 0.708\n",
      "\n",
      "epoch 265\n",
      "Train set - loss: 0.563, accuracy: 0.711\n",
      "Test  set - loss: 0.562, accuracy: 0.709\n",
      "\n",
      "epoch 270\n",
      "Train set - loss: 0.562, accuracy: 0.711\n",
      "Test  set - loss: 0.562, accuracy: 0.71\n",
      "\n",
      "epoch 275\n",
      "Train set - loss: 0.561, accuracy: 0.711\n",
      "Test  set - loss: 0.561, accuracy: 0.71\n",
      "\n",
      "epoch 280\n",
      "Train set - loss: 0.56, accuracy: 0.713\n",
      "Test  set - loss: 0.559, accuracy: 0.712\n",
      "\n",
      "epoch 285\n",
      "Train set - loss: 0.557, accuracy: 0.716\n",
      "Test  set - loss: 0.556, accuracy: 0.715\n",
      "\n",
      "epoch 290\n",
      "Train set - loss: 0.555, accuracy: 0.717\n",
      "Test  set - loss: 0.554, accuracy: 0.718\n",
      "\n",
      "epoch 295\n",
      "Train set - loss: 0.555, accuracy: 0.718\n",
      "Test  set - loss: 0.554, accuracy: 0.721\n",
      "\n",
      "epoch 300\n",
      "Train set - loss: 0.554, accuracy: 0.72\n",
      "Test  set - loss: 0.553, accuracy: 0.723\n",
      "\n",
      "epoch 305\n",
      "Train set - loss: 0.553, accuracy: 0.721\n",
      "Test  set - loss: 0.552, accuracy: 0.724\n",
      "\n",
      "epoch 310\n",
      "Train set - loss: 0.552, accuracy: 0.721\n",
      "Test  set - loss: 0.551, accuracy: 0.724\n",
      "\n",
      "epoch 315\n",
      "Train set - loss: 0.552, accuracy: 0.721\n",
      "Test  set - loss: 0.55, accuracy: 0.724\n",
      "\n",
      "epoch 320\n",
      "Train set - loss: 0.551, accuracy: 0.721\n",
      "Test  set - loss: 0.55, accuracy: 0.724\n",
      "\n",
      "epoch 325\n",
      "Train set - loss: 0.551, accuracy: 0.721\n",
      "Test  set - loss: 0.549, accuracy: 0.725\n",
      "\n",
      "epoch 330\n",
      "Train set - loss: 0.55, accuracy: 0.722\n",
      "Test  set - loss: 0.548, accuracy: 0.725\n",
      "\n",
      "epoch 335\n",
      "Train set - loss: 0.549, accuracy: 0.723\n",
      "Test  set - loss: 0.548, accuracy: 0.726\n",
      "\n",
      "epoch 340\n",
      "Train set - loss: 0.549, accuracy: 0.723\n",
      "Test  set - loss: 0.547, accuracy: 0.726\n",
      "\n",
      "epoch 345\n",
      "Train set - loss: 0.549, accuracy: 0.724\n",
      "Test  set - loss: 0.547, accuracy: 0.727\n",
      "\n",
      "epoch 350\n",
      "Train set - loss: 0.548, accuracy: 0.724\n",
      "Test  set - loss: 0.546, accuracy: 0.727\n",
      "\n",
      "epoch 355\n",
      "Train set - loss: 0.548, accuracy: 0.724\n",
      "Test  set - loss: 0.546, accuracy: 0.727\n",
      "\n",
      "epoch 360\n",
      "Train set - loss: 0.547, accuracy: 0.724\n",
      "Test  set - loss: 0.545, accuracy: 0.727\n",
      "\n",
      "epoch 365\n",
      "Train set - loss: 0.547, accuracy: 0.724\n",
      "Test  set - loss: 0.545, accuracy: 0.727\n",
      "\n",
      "epoch 370\n",
      "Train set - loss: 0.546, accuracy: 0.725\n",
      "Test  set - loss: 0.544, accuracy: 0.728\n",
      "\n",
      "epoch 375\n",
      "Train set - loss: 0.546, accuracy: 0.725\n",
      "Test  set - loss: 0.544, accuracy: 0.729\n",
      "\n",
      "epoch 380\n",
      "Train set - loss: 0.546, accuracy: 0.725\n",
      "Test  set - loss: 0.544, accuracy: 0.729\n",
      "\n",
      "epoch 385\n",
      "Train set - loss: 0.545, accuracy: 0.725\n",
      "Test  set - loss: 0.543, accuracy: 0.729\n",
      "\n",
      "epoch 390\n",
      "Train set - loss: 0.545, accuracy: 0.726\n",
      "Test  set - loss: 0.543, accuracy: 0.73\n",
      "\n",
      "epoch 395\n",
      "Train set - loss: 0.545, accuracy: 0.726\n",
      "Test  set - loss: 0.542, accuracy: 0.73\n",
      "\n",
      "epoch 400\n",
      "Train set - loss: 0.544, accuracy: 0.726\n",
      "Test  set - loss: 0.542, accuracy: 0.73\n",
      "\n",
      "epoch 405\n",
      "Train set - loss: 0.544, accuracy: 0.727\n",
      "Test  set - loss: 0.542, accuracy: 0.73\n",
      "\n",
      "epoch 410\n",
      "Train set - loss: 0.544, accuracy: 0.727\n",
      "Test  set - loss: 0.541, accuracy: 0.73\n",
      "\n",
      "epoch 415\n",
      "Train set - loss: 0.543, accuracy: 0.727\n",
      "Test  set - loss: 0.541, accuracy: 0.73\n",
      "\n",
      "epoch 420\n",
      "Train set - loss: 0.543, accuracy: 0.727\n",
      "Test  set - loss: 0.541, accuracy: 0.73\n",
      "\n",
      "epoch 425\n",
      "Train set - loss: 0.543, accuracy: 0.727\n",
      "Test  set - loss: 0.54, accuracy: 0.731\n",
      "\n",
      "epoch 430\n",
      "Train set - loss: 0.542, accuracy: 0.728\n",
      "Test  set - loss: 0.54, accuracy: 0.731\n",
      "\n",
      "epoch 435\n",
      "Train set - loss: 0.542, accuracy: 0.728\n",
      "Test  set - loss: 0.54, accuracy: 0.732\n",
      "\n",
      "epoch 440\n",
      "Train set - loss: 0.542, accuracy: 0.728\n",
      "Test  set - loss: 0.539, accuracy: 0.731\n",
      "\n",
      "epoch 445\n",
      "Train set - loss: 0.541, accuracy: 0.728\n",
      "Test  set - loss: 0.539, accuracy: 0.732\n",
      "\n",
      "epoch 450\n",
      "Train set - loss: 0.541, accuracy: 0.729\n",
      "Test  set - loss: 0.539, accuracy: 0.731\n",
      "\n",
      "epoch 455\n",
      "Train set - loss: 0.541, accuracy: 0.729\n",
      "Test  set - loss: 0.538, accuracy: 0.732\n",
      "\n",
      "epoch 460\n",
      "Train set - loss: 0.54, accuracy: 0.729\n",
      "Test  set - loss: 0.538, accuracy: 0.732\n",
      "\n",
      "epoch 465\n",
      "Train set - loss: 0.54, accuracy: 0.73\n",
      "Test  set - loss: 0.538, accuracy: 0.732\n",
      "\n",
      "epoch 470\n",
      "Train set - loss: 0.54, accuracy: 0.73\n",
      "Test  set - loss: 0.537, accuracy: 0.733\n",
      "\n",
      "epoch 475\n",
      "Train set - loss: 0.54, accuracy: 0.73\n",
      "Test  set - loss: 0.537, accuracy: 0.733\n",
      "\n",
      "epoch 480\n",
      "Train set - loss: 0.539, accuracy: 0.73\n",
      "Test  set - loss: 0.537, accuracy: 0.733\n",
      "\n",
      "epoch 485\n",
      "Train set - loss: 0.539, accuracy: 0.73\n",
      "Test  set - loss: 0.537, accuracy: 0.733\n",
      "\n",
      "epoch 490\n",
      "Train set - loss: 0.539, accuracy: 0.73\n",
      "Test  set - loss: 0.536, accuracy: 0.733\n",
      "\n",
      "epoch 495\n",
      "Train set - loss: 0.538, accuracy: 0.731\n",
      "Test  set - loss: 0.536, accuracy: 0.733\n",
      "\n",
      "epoch 500\n",
      "Train set - loss: 0.538, accuracy: 0.731\n",
      "Test  set - loss: 0.536, accuracy: 0.734\n",
      "\n",
      "epoch 505\n",
      "Train set - loss: 0.538, accuracy: 0.731\n",
      "Test  set - loss: 0.536, accuracy: 0.734\n",
      "\n",
      "epoch 510\n",
      "Train set - loss: 0.538, accuracy: 0.731\n",
      "Test  set - loss: 0.535, accuracy: 0.733\n",
      "\n",
      "epoch 515\n",
      "Train set - loss: 0.537, accuracy: 0.731\n",
      "Test  set - loss: 0.535, accuracy: 0.733\n",
      "\n",
      "epoch 520\n",
      "Train set - loss: 0.537, accuracy: 0.731\n",
      "Test  set - loss: 0.535, accuracy: 0.734\n",
      "\n",
      "epoch 525\n",
      "Train set - loss: 0.537, accuracy: 0.731\n",
      "Test  set - loss: 0.534, accuracy: 0.734\n",
      "\n",
      "epoch 530\n",
      "Train set - loss: 0.537, accuracy: 0.731\n",
      "Test  set - loss: 0.534, accuracy: 0.735\n",
      "\n",
      "epoch 535\n",
      "Train set - loss: 0.536, accuracy: 0.731\n",
      "Test  set - loss: 0.534, accuracy: 0.735\n",
      "\n",
      "epoch 540\n",
      "Train set - loss: 0.536, accuracy: 0.732\n",
      "Test  set - loss: 0.534, accuracy: 0.735\n",
      "\n",
      "epoch 545\n",
      "Train set - loss: 0.536, accuracy: 0.732\n",
      "Test  set - loss: 0.533, accuracy: 0.735\n",
      "\n",
      "epoch 550\n",
      "Train set - loss: 0.536, accuracy: 0.732\n",
      "Test  set - loss: 0.533, accuracy: 0.735\n",
      "\n",
      "epoch 555\n",
      "Train set - loss: 0.535, accuracy: 0.732\n",
      "Test  set - loss: 0.533, accuracy: 0.736\n",
      "\n",
      "epoch 560\n",
      "Train set - loss: 0.535, accuracy: 0.732\n",
      "Test  set - loss: 0.533, accuracy: 0.735\n",
      "\n",
      "epoch 565\n",
      "Train set - loss: 0.535, accuracy: 0.732\n",
      "Test  set - loss: 0.532, accuracy: 0.736\n",
      "\n",
      "epoch 570\n",
      "Train set - loss: 0.535, accuracy: 0.732\n",
      "Test  set - loss: 0.532, accuracy: 0.736\n",
      "\n",
      "epoch 575\n",
      "Train set - loss: 0.534, accuracy: 0.733\n",
      "Test  set - loss: 0.532, accuracy: 0.736\n",
      "\n",
      "epoch 580\n",
      "Train set - loss: 0.534, accuracy: 0.733\n",
      "Test  set - loss: 0.532, accuracy: 0.737\n",
      "\n",
      "epoch 585\n",
      "Train set - loss: 0.534, accuracy: 0.733\n",
      "Test  set - loss: 0.531, accuracy: 0.737\n",
      "\n",
      "epoch 590\n",
      "Train set - loss: 0.534, accuracy: 0.733\n",
      "Test  set - loss: 0.531, accuracy: 0.737\n",
      "\n",
      "epoch 595\n",
      "Train set - loss: 0.533, accuracy: 0.733\n",
      "Test  set - loss: 0.531, accuracy: 0.737\n",
      "\n",
      "epoch 600\n",
      "Train set - loss: 0.533, accuracy: 0.733\n",
      "Test  set - loss: 0.531, accuracy: 0.737\n",
      "\n",
      "epoch 605\n",
      "Train set - loss: 0.533, accuracy: 0.733\n",
      "Test  set - loss: 0.531, accuracy: 0.737\n",
      "\n",
      "epoch 610\n",
      "Train set - loss: 0.533, accuracy: 0.734\n",
      "Test  set - loss: 0.53, accuracy: 0.737\n",
      "\n",
      "epoch 615\n",
      "Train set - loss: 0.533, accuracy: 0.734\n",
      "Test  set - loss: 0.53, accuracy: 0.736\n",
      "\n",
      "epoch 620\n",
      "Train set - loss: 0.532, accuracy: 0.734\n",
      "Test  set - loss: 0.53, accuracy: 0.737\n",
      "\n",
      "epoch 625\n",
      "Train set - loss: 0.532, accuracy: 0.734\n",
      "Test  set - loss: 0.53, accuracy: 0.738\n",
      "\n",
      "epoch 630\n",
      "Train set - loss: 0.532, accuracy: 0.734\n",
      "Test  set - loss: 0.53, accuracy: 0.737\n",
      "\n",
      "epoch 635\n",
      "Train set - loss: 0.532, accuracy: 0.734\n",
      "Test  set - loss: 0.53, accuracy: 0.737\n",
      "\n",
      "epoch 640\n",
      "Train set - loss: 0.532, accuracy: 0.734\n",
      "Test  set - loss: 0.529, accuracy: 0.737\n",
      "\n",
      "epoch 645\n",
      "Train set - loss: 0.532, accuracy: 0.734\n",
      "Test  set - loss: 0.529, accuracy: 0.737\n",
      "\n",
      "epoch 650\n",
      "Train set - loss: 0.531, accuracy: 0.734\n",
      "Test  set - loss: 0.529, accuracy: 0.737\n",
      "\n",
      "epoch 655\n",
      "Train set - loss: 0.531, accuracy: 0.734\n",
      "Test  set - loss: 0.529, accuracy: 0.737\n",
      "\n",
      "epoch 660\n",
      "Train set - loss: 0.531, accuracy: 0.734\n",
      "Test  set - loss: 0.529, accuracy: 0.737\n",
      "\n",
      "epoch 665\n",
      "Train set - loss: 0.531, accuracy: 0.734\n",
      "Test  set - loss: 0.529, accuracy: 0.738\n",
      "\n",
      "epoch 670\n",
      "Train set - loss: 0.531, accuracy: 0.734\n",
      "Test  set - loss: 0.528, accuracy: 0.738\n",
      "\n",
      "epoch 675\n",
      "Train set - loss: 0.531, accuracy: 0.734\n",
      "Test  set - loss: 0.528, accuracy: 0.738\n",
      "\n",
      "epoch 680\n",
      "Train set - loss: 0.53, accuracy: 0.734\n",
      "Test  set - loss: 0.528, accuracy: 0.738\n",
      "\n",
      "epoch 685\n",
      "Train set - loss: 0.53, accuracy: 0.734\n",
      "Test  set - loss: 0.528, accuracy: 0.738\n",
      "\n",
      "epoch 690\n",
      "Train set - loss: 0.53, accuracy: 0.734\n",
      "Test  set - loss: 0.528, accuracy: 0.739\n",
      "\n",
      "epoch 695\n",
      "Train set - loss: 0.53, accuracy: 0.735\n",
      "Test  set - loss: 0.528, accuracy: 0.739\n",
      "\n",
      "epoch 700\n",
      "Train set - loss: 0.53, accuracy: 0.735\n",
      "Test  set - loss: 0.528, accuracy: 0.738\n",
      "\n",
      "epoch 705\n",
      "Train set - loss: 0.53, accuracy: 0.735\n",
      "Test  set - loss: 0.528, accuracy: 0.738\n",
      "\n",
      "epoch 710\n",
      "Train set - loss: 0.53, accuracy: 0.735\n",
      "Test  set - loss: 0.528, accuracy: 0.739\n",
      "\n",
      "epoch 715\n",
      "Train set - loss: 0.53, accuracy: 0.735\n",
      "Test  set - loss: 0.528, accuracy: 0.739\n",
      "\n",
      "epoch 720\n",
      "Train set - loss: 0.53, accuracy: 0.735\n",
      "Test  set - loss: 0.528, accuracy: 0.739\n",
      "\n",
      "epoch 725\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 730\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 735\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 740\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 745\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 750\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 755\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 760\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 765\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 770\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 775\n",
      "Train set - loss: 0.529, accuracy: 0.735\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 780\n",
      "Train set - loss: 0.529, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 785\n",
      "Train set - loss: 0.529, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 790\n",
      "Train set - loss: 0.529, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 795\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 800\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.738\n",
      "\n",
      "epoch 805\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 810\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 815\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 820\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 825\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 830\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.738\n",
      "\n",
      "epoch 835\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.738\n",
      "\n",
      "epoch 840\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.738\n",
      "\n",
      "epoch 845\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.738\n",
      "\n",
      "epoch 850\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 855\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.738\n",
      "\n",
      "epoch 860\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.738\n",
      "\n",
      "epoch 865\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.527, accuracy: 0.739\n",
      "\n",
      "epoch 870\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 875\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 880\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 885\n",
      "Train set - loss: 0.528, accuracy: 0.737\n",
      "Test  set - loss: 0.526, accuracy: 0.739\n",
      "\n",
      "epoch 890\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.739\n",
      "\n",
      "epoch 895\n",
      "Train set - loss: 0.528, accuracy: 0.737\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 900\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.739\n",
      "\n",
      "epoch 905\n",
      "Train set - loss: 0.528, accuracy: 0.737\n",
      "Test  set - loss: 0.526, accuracy: 0.739\n",
      "\n",
      "epoch 910\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 915\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 920\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 925\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 930\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 935\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 940\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 945\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 950\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.737\n",
      "\n",
      "epoch 955\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 960\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 965\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.739\n",
      "\n",
      "epoch 970\n",
      "Train set - loss: 0.528, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 975\n",
      "Train set - loss: 0.527, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 980\n",
      "Train set - loss: 0.527, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 985\n",
      "Train set - loss: 0.527, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 990\n",
      "Train set - loss: 0.527, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n",
      "epoch 995\n",
      "Train set - loss: 0.527, accuracy: 0.736\n",
      "Test  set - loss: 0.526, accuracy: 0.738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    y_pred = net(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    if epoch % 5 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_test_pred = net(X_test)\n",
    "      y_test_pred = torch.squeeze(y_test_pred)\n",
    "      test_loss = criterion(y_test_pred, y_test)\n",
    "      test_acc = calculate_accuracy(y_test, y_test_pred)\n",
    "      print(\n",
    "f'''epoch {epoch}\n",
    "Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n",
    "''')\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ewaluacja Modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No rain       0.73      0.76      0.74      6036\n",
      "     Raining       0.75      0.72      0.73      6028\n",
      "\n",
      "    accuracy                           0.74     12064\n",
      "   macro avg       0.74      0.74      0.74     12064\n",
      "weighted avg       0.74      0.74      0.74     12064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ['No rain', 'Raining']\n",
    "y_pred = net(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "hmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
